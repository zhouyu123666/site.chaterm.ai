import{_ as e,c as o,o as a,a1 as r}from"./chunks/framework.DDNAyvCW.js";const u=JSON.parse('{"title":"ğŸš€ Model List","description":"","frontmatter":{},"headers":[],"relativePath":"docs/models/index.md","filePath":"docs/models/index.md"}'),i={name:"docs/models/index.md"};function n(d,t,s,l,c,g){return a(),o("div",null,t[0]||(t[0]=[r('<h1 id="ğŸš€-model-list" tabindex="-1">ğŸš€ Model List <a class="header-anchor" href="#ğŸš€-model-list" aria-label="Permalink to &quot;ğŸš€ Model List&quot;">â€‹</a></h1><p>Chaterm supports multiple model providers, offering you a flexible AI programming experience. From built-in models to custom integrations, meeting different scenario needs.</p><h2 id="âœ¨-built-in-models" tabindex="-1">âœ¨ Built-in Models <a class="header-anchor" href="#âœ¨-built-in-models" aria-label="Permalink to &quot;âœ¨ Built-in Models&quot;">â€‹</a></h2><p>Chaterm comes with multiple high-quality code models out of the box, ready to use without additional configuration:</p><h3 id="ğŸ§ -chain-of-thought-models" tabindex="-1">ğŸ§  Chain-of-Thought Models <a class="header-anchor" href="#ğŸ§ -chain-of-thought-models" aria-label="Permalink to &quot;ğŸ§  Chain-of-Thought Models&quot;">â€‹</a></h3><p>These models have deep reasoning capabilities and can analyze problems step by step to provide detailed solutions:</p><table tabindex="0"><thead><tr><th>Model</th><th>Features</th><th>Use Cases</th><th>Reasoning Ability</th></tr></thead><tbody><tr><td><strong>DeepSeek-R1 (thinking)</strong></td><td>ğŸ¯ Advanced model with deep reasoning capabilities</td><td>Complex algorithm design, architecture analysis</td><td>â­â­â­â­â­</td></tr><tr><td><strong>DeepSeek-V3.1 (thinking)</strong></td><td>ğŸ’¡ Supports complex code analysis</td><td>Large project refactoring, performance optimization</td><td>â­â­â­â­â­</td></tr><tr><td><strong>GLM-4.5 (thinking)</strong></td><td>ğŸ” Powerful logical reasoning capabilities</td><td>Code review, problem diagnosis</td><td>â­â­â­â­</td></tr><tr><td><strong>Qwen-Plus (thinking)</strong></td><td>ğŸš€ Alibaba Cloud&#39;s Tongyi Qianwen chain-of-thought model</td><td>Multi-language development, cross-platform projects</td><td>â­â­â­â­</td></tr></tbody></table><h3 id="âš¡-standard-models" tabindex="-1">âš¡ Standard Models <a class="header-anchor" href="#âš¡-standard-models" aria-label="Permalink to &quot;âš¡ Standard Models&quot;">â€‹</a></h3><p>Fast-response standard models suitable for daily programming tasks:</p><table tabindex="0"><thead><tr><th>Model</th><th>Features</th><th>Use Cases</th><th>Response Speed</th></tr></thead><tbody><tr><td><strong>GLM-4.5</strong></td><td>ğŸ¨ Excellent code generation capabilities</td><td>Rapid prototyping, feature implementation</td><td>âš¡âš¡âš¡âš¡</td></tr><tr><td><strong>Qwen-Plus</strong></td><td>ğŸ† High-performance code generation model</td><td>Enterprise application development</td><td>âš¡âš¡âš¡</td></tr><tr><td><strong>Qwen-Turbo</strong></td><td>âš¡ Fast-response lightweight model</td><td>Real-time programming assistance, rapid iteration</td><td>âš¡âš¡âš¡âš¡âš¡</td></tr></tbody></table><h2 id="ğŸ”§-add-custom-models" tabindex="-1">ğŸ”§ Add Custom Models <a class="header-anchor" href="#ğŸ”§-add-custom-models" aria-label="Permalink to &quot;ğŸ”§ Add Custom Models&quot;">â€‹</a></h2><p>You can add more model providers in settings to extend Chaterm&#39;s functionality. Supports multiple integration methods to meet different needs:</p><h3 id="ğŸŒ-cloud-model-integration" tabindex="-1">ğŸŒ Cloud Model Integration <a class="header-anchor" href="#ğŸŒ-cloud-model-integration" aria-label="Permalink to &quot;ğŸŒ Cloud Model Integration&quot;">â€‹</a></h3><h4 id="_1-ğŸ”—-litellm-integration" tabindex="-1">1. ğŸ”— LiteLLM Integration <a class="header-anchor" href="#_1-ğŸ”—-litellm-integration" aria-label="Permalink to &quot;1. ğŸ”— LiteLLM Integration&quot;">â€‹</a></h4><p>Connect to various model providers through LiteLLM with unified API interface:</p><table tabindex="0"><thead><tr><th>Configuration Item</th><th>Description</th><th>Required</th></tr></thead><tbody><tr><td><strong>URL Address</strong></td><td>LiteLLM service endpoint</td><td>âœ… Required</td></tr><tr><td><strong>API Key</strong></td><td>Access key</td><td>âœ… Required</td></tr><tr><td><strong>Model Name</strong></td><td>Specific model to use</td><td>âœ… Required</td></tr></tbody></table><p><strong>Advantages:</strong> Unified interface, supports multiple model providers</p><h4 id="_2-ğŸ¤–-openai-integration" tabindex="-1">2. ğŸ¤– OpenAI Integration <a class="header-anchor" href="#_2-ğŸ¤–-openai-integration" aria-label="Permalink to &quot;2. ğŸ¤– OpenAI Integration&quot;">â€‹</a></h4><p>Direct connection to OpenAI services with official support:</p><table tabindex="0"><thead><tr><th>Configuration Item</th><th>Description</th><th>Required</th></tr></thead><tbody><tr><td><strong>OpenAI URL Address</strong></td><td>OpenAI API endpoint</td><td>âœ… Required</td></tr><tr><td><strong>OpenAI API Key</strong></td><td>OpenAI access key</td><td>âœ… Required</td></tr><tr><td><strong>Model Name</strong></td><td>GPT-4, GPT-3.5, etc.</td><td>âœ… Required</td></tr></tbody></table><p><strong>Advantages:</strong> Official support, stable and reliable</p><h4 id="_3-â˜ï¸-amazon-bedrock" tabindex="-1">3. â˜ï¸ Amazon Bedrock <a class="header-anchor" href="#_3-â˜ï¸-amazon-bedrock" aria-label="Permalink to &quot;3. â˜ï¸ Amazon Bedrock&quot;">â€‹</a></h4><p>Using AWS Bedrock services, enterprise-grade solution:</p><table tabindex="0"><thead><tr><th>Configuration Item</th><th>Description</th><th>Required</th></tr></thead><tbody><tr><td><strong>AWS Access Key</strong></td><td>AWS access key</td><td>âœ… Required</td></tr><tr><td><strong>AWS Secret Key</strong></td><td>AWS secret key</td><td>âœ… Required</td></tr><tr><td><strong>AWS Session Token</strong></td><td>Session token</td><td>ğŸ”¶ Optional</td></tr><tr><td><strong>AWS Region</strong></td><td>Service region</td><td>âœ… Required</td></tr><tr><td><strong>Custom VPC Endpoint</strong></td><td>Private network endpoint</td><td>ğŸ”¶ Optional</td></tr><tr><td><strong>Cross-Region Inference</strong></td><td>Multi-region deployment</td><td>ğŸ”¶ Optional</td></tr><tr><td><strong>Model Name</strong></td><td>Bedrock model</td><td>âœ… Required</td></tr></tbody></table><p><strong>Advantages:</strong> Enterprise-grade security, high availability</p><h4 id="_4-ğŸš€-deepseek-integration" tabindex="-1">4. ğŸš€ DeepSeek Integration <a class="header-anchor" href="#_4-ğŸš€-deepseek-integration" aria-label="Permalink to &quot;4. ğŸš€ DeepSeek Integration&quot;">â€‹</a></h4><p>Connect to DeepSeek official API, enjoy advanced models:</p><table tabindex="0"><thead><tr><th>Configuration Item</th><th>Description</th><th>Required</th></tr></thead><tbody><tr><td><strong>DeepSeek API Key</strong></td><td>DeepSeek access key</td><td>âœ… Required</td></tr><tr><td><strong>Model Name</strong></td><td>DeepSeek model</td><td>âœ… Required</td></tr></tbody></table><p><strong>Advantages:</strong> Advanced models, strong reasoning capabilities</p><h3 id="ğŸ -local-model-deployment" tabindex="-1">ğŸ  Local Model Deployment <a class="header-anchor" href="#ğŸ -local-model-deployment" aria-label="Permalink to &quot;ğŸ  Local Model Deployment&quot;">â€‹</a></h3><h4 id="_5-ğŸ¦™-ollama-local-deployment" tabindex="-1">5. ğŸ¦™ Ollama Local Deployment <a class="header-anchor" href="#_5-ğŸ¦™-ollama-local-deployment" aria-label="Permalink to &quot;5. ğŸ¦™ Ollama Local Deployment&quot;">â€‹</a></h4><p>Using locally deployed Ollama models, protect data privacy:</p><table tabindex="0"><thead><tr><th>Configuration Item</th><th>Description</th><th>Required</th></tr></thead><tbody><tr><td><strong>Ollama URL Address</strong></td><td>Local Ollama service address</td><td>âœ… Required</td></tr><tr><td><strong>Model Name</strong></td><td>Local model name</td><td>âœ… Required</td></tr></tbody></table><p><strong>Advantages:</strong> Data privacy, offline available</p><h2 id="ğŸ“‹-usage-instructions" tabindex="-1">ğŸ“‹ Usage Instructions <a class="header-anchor" href="#ğŸ“‹-usage-instructions" aria-label="Permalink to &quot;ğŸ“‹ Usage Instructions&quot;">â€‹</a></h2><h3 id="quick-start" tabindex="-1">Quick Start <a class="header-anchor" href="#quick-start" aria-label="Permalink to &quot;Quick Start&quot;">â€‹</a></h3><ol><li><strong>Go to Settings Page</strong> - Click the settings icon in the top right corner</li><li><strong>Select &quot;Models&quot; Tab</strong> - Find model settings in the left menu</li><li><strong>Click &quot;Add Model&quot; Button</strong> - Start adding new model configuration</li><li><strong>Choose the Corresponding Provider</strong> - Select appropriate model provider based on needs</li><li><strong>Fill in Necessary Configuration Information</strong> - Fill in configuration items according to table requirements</li><li><strong>Save and Test Connection</strong> - Verify configuration is correct</li></ol><h3 id="ğŸ”§-configuration-tips" tabindex="-1">ğŸ”§ Configuration Tips <a class="header-anchor" href="#ğŸ”§-configuration-tips" aria-label="Permalink to &quot;ğŸ”§ Configuration Tips&quot;">â€‹</a></h3><ul><li><strong>API Key Security</strong>: Use environment variables to store sensitive information</li><li><strong>Connection Testing</strong>: Always perform connection test after configuration</li><li><strong>Model Switching</strong>: Configure multiple models and switch as needed</li><li><strong>Performance Monitoring</strong>: Monitor model response time and usage costs</li></ul><h2 id="ğŸ¯-model-selection-recommendations" tabindex="-1">ğŸ¯ Model Selection Recommendations <a class="header-anchor" href="#ğŸ¯-model-selection-recommendations" aria-label="Permalink to &quot;ğŸ¯ Model Selection Recommendations&quot;">â€‹</a></h2><h3 id="select-by-use-case" tabindex="-1">Select by Use Case <a class="header-anchor" href="#select-by-use-case" aria-label="Permalink to &quot;Select by Use Case&quot;">â€‹</a></h3><table tabindex="0"><thead><tr><th>Use Case</th><th>Recommended Model</th><th>Reason</th></tr></thead><tbody><tr><td><strong>Daily Programming</strong></td><td>Qwen-Turbo</td><td>âš¡ Fast response, low cost</td></tr><tr><td><strong>Complex Tasks</strong></td><td>DeepSeek-R1 (thinking)</td><td>ğŸ§  Strong reasoning capabilities, deep analysis</td></tr><tr><td><strong>Local Deployment</strong></td><td>Ollama</td><td>ğŸ”’ Data privacy, offline available</td></tr><tr><td><strong>Enterprise Applications</strong></td><td>Amazon Bedrock</td><td>ğŸ¢ Stable and reliable, security compliant</td></tr><tr><td><strong>Multi-language Development</strong></td><td>Qwen-Plus (thinking)</td><td>ğŸŒ Multi-language support, strong understanding</td></tr><tr><td><strong>Rapid Prototyping</strong></td><td>GLM-4.5</td><td>ğŸš€ Fast generation, suitable for iteration</td></tr></tbody></table><h3 id="select-by-performance-needs" tabindex="-1">Select by Performance Needs <a class="header-anchor" href="#select-by-performance-needs" aria-label="Permalink to &quot;Select by Performance Needs&quot;">â€‹</a></h3><h4 id="ğŸš€-pursuing-speed" tabindex="-1">ğŸš€ Pursuing Speed <a class="header-anchor" href="#ğŸš€-pursuing-speed" aria-label="Permalink to &quot;ğŸš€ Pursuing Speed&quot;">â€‹</a></h4><ul><li><strong>Qwen-Turbo</strong> - Fastest response</li><li><strong>GLM-4.5</strong> - Balanced performance and quality</li></ul><h4 id="ğŸ§ -pursuing-quality" tabindex="-1">ğŸ§  Pursuing Quality <a class="header-anchor" href="#ğŸ§ -pursuing-quality" aria-label="Permalink to &quot;ğŸ§  Pursuing Quality&quot;">â€‹</a></h4><ul><li><strong>DeepSeek-R1 (thinking)</strong> - Strongest reasoning</li><li><strong>DeepSeek-V3.1 (thinking)</strong> - Complex analysis</li></ul><h4 id="ğŸ’°-pursuing-cost-efficiency" tabindex="-1">ğŸ’° Pursuing Cost Efficiency <a class="header-anchor" href="#ğŸ’°-pursuing-cost-efficiency" aria-label="Permalink to &quot;ğŸ’° Pursuing Cost Efficiency&quot;">â€‹</a></h4><ul><li><strong>Qwen-Turbo</strong> - Lowest cost</li><li><strong>Ollama Local</strong> - No usage fees</li></ul><h4 id="ğŸ”’-pursuing-privacy" tabindex="-1">ğŸ”’ Pursuing Privacy <a class="header-anchor" href="#ğŸ”’-pursuing-privacy" aria-label="Permalink to &quot;ğŸ”’ Pursuing Privacy&quot;">â€‹</a></h4><ul><li><strong>Ollama Local</strong> - Complete localization</li><li><strong>Amazon Bedrock</strong> - Enterprise-grade security</li></ul><h2 id="ğŸ’¡-best-practices" tabindex="-1">ğŸ’¡ Best Practices <a class="header-anchor" href="#ğŸ’¡-best-practices" aria-label="Permalink to &quot;ğŸ’¡ Best Practices&quot;">â€‹</a></h2><h3 id="model-combination-usage" tabindex="-1">Model Combination Usage <a class="header-anchor" href="#model-combination-usage" aria-label="Permalink to &quot;Model Combination Usage&quot;">â€‹</a></h3><ul><li><strong>Development Phase</strong>: Use fast models for rapid iteration</li><li><strong>Code Review</strong>: Use chain-of-thought models for deep analysis</li><li><strong>Production Environment</strong>: Use stable and reliable enterprise-grade models</li></ul><h3 id="cost-optimization" tabindex="-1">Cost Optimization <a class="header-anchor" href="#cost-optimization" aria-label="Permalink to &quot;Cost Optimization&quot;">â€‹</a></h3><ul><li><strong>Local Models</strong>: Suitable for frequently used scenarios</li><li><strong>Cloud Models</strong>: Suitable for occasional complex tasks</li><li><strong>Hybrid Usage</strong>: Choose appropriate models based on task complexity</li></ul><h3 id="security-considerations" tabindex="-1">Security Considerations <a class="header-anchor" href="#security-considerations" aria-label="Permalink to &quot;Security Considerations&quot;">â€‹</a></h3><ul><li><strong>Sensitive Data</strong>: Prioritize local models</li><li><strong>Enterprise Environment</strong>: Use compliance-compliant models</li><li><strong>API Security</strong>: Regularly rotate API keys</li></ul>',58)]))}const p=e(i,[["render",n]]);export{u as __pageData,p as default};
